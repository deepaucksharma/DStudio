# The Compendium of Distributed Systems: Comprehensive First-Principles Expansion

!!! abstract "Core Philosophy"
    **All distributed systems behavior emerges from physical and mathematical constraints**. Rather than teaching patterns as recipes, we derive them from immutable laws.

## Response 1: Foundation, Philosophy, and Front Matter

### Core First-Principles Philosophy

<div class="axiom-box">

The entire book is built on fundamental constraints:

1. **Physical Laws**: Speed of light, thermodynamics, information theory
2. **Mathematical Laws**: Queueing theory, probability, graph theory
3. **Economic Laws**: Cost gradients, opportunity costs, resource allocation
4. **Human Laws**: Cognitive limits, communication bandwidth, organizational dynamics

</div>

### First-Principles Learning Framework

```mermaid
graph LR
    A[Fundamental Constraint] --> B[Emergent Behavior]
    B --> C[System Impact]
    C --> D[Design Pattern]
    D --> E[Trade-off Decision]
    style A fill:#E3F2FD,stroke:#1976D2
    style B fill:#F3E5F5,stroke:#7B1FA2
    style C fill:#FFF3E0,stroke:#F57C00
    style D fill:#E8F5E9,stroke:#388E3C
    style E fill:#FFEBEE,stroke:#D32F2F
```

---

## EXPANDED FRONT MATTER (Pages i-iv)

### Pages i-ii: COVER, COPYRIGHT & CREDITS

=== "Visual Design Philosophy"

    - **Cover art**: A visual metaphor of light beams hitting a prism, splitting into the spectrum of distributed systems patterns
    - Each color represents an axiom, showing how white light (monolithic systems) splits into the distributed spectrum
    - QR code links to interactive simulator where readers can adjust axiom parameters and see pattern emergence

=== "Copyright Innovation"

    - CC-BY-NC license with "Derivative Works Encouraged" clause
    - Special provision for corporate training use with attribution
    - Living document commitment: purchasers get 3 years of updates

=== "Credits Structure"

    - Technical reviewers grouped by expertise (Theory, Practice, Pedagogy)
    - Beta reader testimonials with role/experience level
    - Special thanks to failure story contributors (anonymized)

### Page iii: PREFACE ‚Äì Why Another Systems Book?

!!! quote "400-Word Manifesto"
    Existing distributed systems literature falls into two camps: academic proofs divorced from practice, or engineering cookbooks lacking theoretical foundation. DDIA gives you the 'what' and 'how'; SRE books provide the 'when things break.' This book uniquely provides the 'why from first principles.'

    We don't start with Kafka or Kubernetes. We start with the speed of light and the laws of thermodynamics. Every pattern emerges from inescapable constraints. When you understand why coordination has fundamental costs, you'll never again wonder whether to use 2PC or saga patterns‚Äîthe physics will tell you.
    Three breakthroughs make this approach finally practical:
    
    1. **Axiom Unification**: Eight fundamental constraints explain all distributed behavior
    2. **Pattern Derivation**: Every architecture pattern emerges from axiom combinations
    3. **Decision Calculus**: Quantitative trade-off framework replacing intuition with math

    This isn't another 500-page tome to read once. It's a 100-page compass you'll reference throughout your career. Each page earns its place through information density and immediate applicability.

??? info "Scope Boundaries"
    **IN SCOPE:**
    
    - Distributed systems from 2-node to planet-scale
    - Both synchronous and asynchronous architectures
    
    **OUT OF SCOPE:**
    
    - Single-node optimization (refer to Hennessy & Patterson)
    - Specific vendor products (patterns over products)
    - Full protocol specifications (we extract principles)

### Page iv: READER ROAD-MAP

<div class="metro-map">

```mermaid
graph TD
    Start[START] --> NewGrad[NEW GRAD LINE]
    Start --> Senior[SENIOR IC LINE]
    Start --> Manager[ENG MANAGER LINE]
    Start --> Express[EXPRESS ROUTE]
    
    NewGrad -->|Green Line| A1[Axioms 1-3]
    A1 --> A2[Work Distribution]
    A2 --> A3[Queues]
    A3 --> A4[Retries]
    A4 --> A5[Case 1]
    A5 --> Practitioner[PRACTITIONER]    
    Senior -->|Blue Line| B1[All Axioms]
    B1 --> B2[All Pillars]
    B2 --> B3[Patterns 45-64]
    B3 --> B4[Quant Tools]
    B4 --> B5[Cases]
    B5 --> Architect[ARCHITECT]
    
    Manager -->|Orange Line| C1[Axioms 1,3,7,8]
    C1 --> C2[Pillars Overview]
    C2 --> C3[Human Factors]
    C3 --> C4[Org Physics]
    C4 --> C5[Cases]
    C5 --> Leader[LEADER]
    
    Express -->|Red Line| D1[Spider Chart]
    D1 --> D2[Decision Tree]
    D2 --> D3[Relevant Pattern]
    D3 --> D4[Worked Example]
    D4 --> Solution[SOLUTION]
    
    style NewGrad fill:#4CAF50,color:#fff
    style Senior fill:#2196F3,color:#fff
    style Manager fill:#FF9800,color:#fff
    style Express fill:#F44336,color:#fff
```

</div>

<div class="icon-legend">
<div class="icon-item"><span>üéØ</span><strong>Decision Point:</strong> Major architectural choice</div>
<div class="icon-item"><span>‚ö†Ô∏è</span><strong>Common Pitfall:</strong> Where systems typically fail</div>
<div class="icon-item"><span>üí°</span><strong>Insight Box:</strong> Counter-intuitive truth</div>
<div class="icon-item"><span>üîß</span><strong>Try This:</strong> Hands-on exercise (<5 min)</div>
<div class="icon-item"><span>üìä</span><strong>Measure This:</strong> Instrumentation point</div>
<div class="icon-item"><span>üé¨</span><strong>Real Story:</strong> Anonymized failure vignette</div>
<div class="icon-item"><span>üßÆ</span><strong>Calculate:</strong> Numerical example</div>
<div class="icon-item"><span>üîó</span><strong>Cross-Link:</strong> Related concept elsewhere</div>
</div>

!!! success "Learning Commitment"
    Each page promises ONE core insight you'll use within 30 days

---

## PART I: AXIOM-BASED FOUNDATION (Pages 1-20)

### Page 1: AXIOM 1 ‚Äì Latency (Speed of Light)

!!! target "Learning Objective"
    Internalize that latency is physics, not engineering.

#### Core Content Structure

<div class="axiom-box">

**Definition:**

```
Latency := Time for information to travel from point A to point B
Minimum Bound: distance / speed_of_light
In fiber: ~200,000 km/s (2/3 of c due to refractive index)
```

</div>

**The Physics Foundation:**

| Medium | Speed | Note |
|--------|-------|------|
| Light in vacuum | 299,792 km/s | Theoretical maximum |
| Fiber optic cable | ~200,000 km/s | Refractive index slowdown |
| Copper wire | ~200,000 km/s | Electromagnetic wave |

!!! danger "Fundamental Insight"
    No engineering can overcome physics

<div class="failure-vignette">

**Failure Vignette: The Tokyo Checkout Disaster**

```yaml
Scene: Black Friday 2019, US e-commerce giant
Setup: "Smart" optimization routes all Asian traffic to Tokyo DC
Problem: SF inventory DB is source of truth
Impact: 250ms RTT √ó 3 DB calls = 750ms per checkout
Result: 67% cart abandonment, $12M lost revenue
Fix: Regional inventory caches with eventual consistency
Lesson: Speed of light is a budget, not a suggestion
```

</div>

<div class="latency-ladder">

**The Latency Ladder** ü™ú

```
Same rack:          0.5 ms    ‚ñì
Same DC:            1-2 ms    ‚ñì‚ñì
Same region:        10 ms     ‚ñì‚ñì‚ñì‚ñì‚ñì
Cross-continent:    100 ms    ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
Opposite globe:     200+ ms   ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
Geosync satellite:  500+ ms   ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
Mars (best case):   4 min     ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
```

</div>

<div class="decision-box">

**üéØ Decision Box: Cache vs Replica**

```python
IF (latency_budget < physics_minimum) THEN
  IF (data_changes_rarely) THEN
    USE cache WITH ttl = change_frequency
  ELSE IF (eventual_consistency_ok) THEN
    USE read_replica WITH async_replication
  ELSE
    REDESIGN to avoid remote calls
  END
ELSE
  USE remote_calls WITH latency_budget - physics_minimum margin
END
```

</div>

!!! example "Interactive Element"
    - Globe visualization with draggable points
    - Shows theoretical minimum latency between any two points
    - Overlays actual internet paths vs great circle routes

??? tip "üîß Try This (2 minutes)"
    ```bash
    # Measure your physics tax
    ping -c 10 google.com | grep "min/avg/max"
    traceroute google.com | tail -5
    # Calculate: actual_latency / theoretical_minimum
    ```

<div class="truth-box">

**Counter-Intuitive Truth** üí°

Adding more servers can INCREASE latency if it adds more hops. The fastest distributed system is often the one with fewer, better-placed nodes.

</div>

!!! info "Cross-Links"
    - ‚Üí [Caching Hierarchies (p.57)](#): Implementation patterns
    - ‚Üí [Geo-Replication (p.61)](#): Multi-region strategies  
    - ‚Üí [Latency Budget Worksheet (p.2)](#page-2-latency-budget-worksheet): Practical application

---

### Page 2: Latency Budget Worksheet

!!! abstract "Purpose"
    Transform latency from abstract concept to concrete budget.

#### The Latency P&L Statement

=== "Revenue (Total Budget)"
    ```
    User Expectation:        [___] ms
    Minus Browser Render:    -50 ms
    Minus Network Last Mile: -20 ms
    = Backend Budget:        [___] ms
    ```

=== "Expenses (Allocations)"
    ```
    Load Balancer:     [___] ms (typical: 1-2)
    API Gateway:       [___] ms (typical: 2-5)
    Service Mesh:      [___] ms (typical: 1-3)
    Business Logic:    [___] ms (varies)
    Database Call:     [___] ms (typical: 5-50)
    Cache Check:       [___] ms (typical: 0.5-2)
    Total Spent:       [___] ms
    ```

=== "Margin"
    ```
    MARGIN: [___] ms (must be > 0!)
    ```

#### Real-World Budgets by Industry

| Industry | Budget | Reason |
|----------|--------|--------|
| **Stock Trading** | 10 ms | Regulatory requirement |
| **Gaming** | 16 ms | 60 fps requirement |
| **Video Conference** | 150 ms | Conversation flow |
| **E-commerce** | 1000 ms | Conversion dropoff |
| **Email** | 5000 ms | User expectation |

??? example "üßÆ Worked Example: Photo Sharing App"
    **Goal**: User uploads photo, expects thumbnail in < 2 seconds
    
    **Budget Allocation**:
    ```yaml
    Upload to CDN edge:      100 ms  (physics: user to edge)
    Edge to origin DC:        50 ms  (physics: edge to DC)
    Queue wait time:         200 ms  (p95 during peak)
    Resize processing:       500 ms  (CPU bound)
    Thumbnail generation:    300 ms  (GPU accelerated)
    Write to 3 replicas:     150 ms  (parallel writes)
    CDN cache population:    200 ms  (push to edges)
    Response to user:        100 ms  (physics: edge to user)
    ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
    TOTAL:                  1600 ms  ‚úÖ (400ms margin)
    ```
    
    **Optimization opportunities**:
    
    1. Pre-warm GPU containers (-200ms cold start)
    2. Regional processing (-50ms physics tax)
    3. Optimistic UI (-1600ms perceived!)

!!! warning "Budget Violation Patterns"
    1. **Death by Thousand Cuts**: Each service "only" adds 5ms
    2. **Retry Multiplication**: 3 retries √ó 100ms = 300ms gone
    3. **Serial Staircase**: Waterfall instead of parallel
    4. **Cold Start Surprise**: Lambda/container warm-up
    5. **GC Pause Gambling**: 99th percentile GC stops

??? tip "üîß Try This: Profile Your Critical Path"
    ```python
    import time
    from contextlib import contextmanager

    @contextmanager
    def latency_budget(operation, budget_ms):
        start = time.time()
        yield
        elapsed_ms = (time.time() - start) * 1000
        remaining = budget_ms - elapsed_ms
        print(f"{operation}: {elapsed_ms:.1f}ms (budget: {remaining:+.1f}ms)")
        if remaining < 0:
            print(f"‚ö†Ô∏è  BUDGET VIOLATION: {-remaining:.1f}ms over!")

    # Use in your code:
    with latency_budget("Database query", 50):
        results = db.query("SELECT ...")
    ```

---

### Page 3: AXIOM 2 ‚Äì Finite Capacity

!!! target "Learning Objective"
    Every resource has a breaking point; find it before production does.

<div class="axiom-box">

**Core Principle:**

```
Every system component has finite:
- CPU cycles per second
- Memory bytes
- Network packets/sec  
- Disk IOPS
- Connection pool slots
- Thread count
- Queue depth

Corollary: Infinite scaling is a lie sold by cloud vendors
```

</div>

!!! quote "The Thermodynamics Angle"
    Just as energy cannot be created or destroyed, computational capacity cannot be materialized from nothing. It can only be moved (migration), transformed (optimization), or purchased (scaling).

<div class="failure-vignette">

**Failure Vignette: Black Friday Database Meltdown**

```yaml
Company: Major retailer, $2B revenue
Date: Black Friday 2021, 6:00 AM EST
Sequence:
  06:00: Marketing sends "50% off everything" email
  06:01: 2M users click simultaneously  
  06:02: API servers scale from 100 to 1000 pods
  06:03: Each pod opens 10 connections to DB
  06:04: Database connection limit: 5000
  06:05: 10,000 connections attempted
  06:06: Database rejects new connections
  06:07: Health checks fail, cascading restarts
  06:15: Site completely down
  08:00: Manual intervention restores service
  
Loss: $50M in sales, brand damage

Root Cause: Scaled compute, forgot DB connections are finite
Fix: Connection pooling, admission control, backpressure
```

</div>

#### The Capacity Staircase

```mermaid
graph LR
    subgraph "Level 1: Single Server"
        A[16 cores = 16 parallel ops<br/>64GB RAM = ~1M sessions<br/>10Gbps NIC = 1.25GB/sec]
    end
    
    subgraph "Level 2: Distributed"
        B[20-30% coordination overhead<br/>Network bottlenecks<br/>Storage contention]
    end
    
    subgraph "Level 3: Planetary"
        C[Speed of light delays<br/>CAP theorem trade-offs<br/>Human operator limits]
    end
    
    A -->|Scale Out| B
    B -->|Global Scale| C
    
    style A fill:#E8F5E9,stroke:#4CAF50
    style B fill:#FFF3E0,stroke:#FF9800
    style C fill:#FFEBEE,stroke:#F44336
```

<div class="decision-box">

**üéØ Decision Tree: Scale-Up vs Scale-Out**

```
START: Need more capacity
  ‚îÇ
  ‚îú‚îÄ Is workload parallelizable?
  ‚îÇ   ‚îú‚îÄ NO ‚Üí Scale UP (bigger box)
  ‚îÇ   ‚îî‚îÄ YES ‚Üí Continue
  ‚îÇ
  ‚îú‚îÄ Is data easily partitioned?
  ‚îÇ   ‚îú‚îÄ NO ‚Üí Scale UP + Read replicas
  ‚îÇ   ‚îî‚îÄ YES ‚Üí Continue  
  ‚îÇ
  ‚îú‚îÄ Can tolerate eventual consistency?
  ‚îÇ   ‚îú‚îÄ NO ‚Üí Scale UP to limits, then shard carefully
  ‚îÇ   ‚îî‚îÄ YES ‚Üí Scale OUT (add nodes)
  ‚îÇ
  ‚îî‚îÄ Result: Your scaling strategy
```

</div>

#### Capacity Arithmetic

=== "Formula"
    ```
    Effective Capacity = Raw Capacity √ó Utilization Factor √ó Efficiency Factor
    
    Where:
    - Utilization Factor = 1 - (idle + overhead)
    - Efficiency Factor = 1 / (1 + coordination_cost)
    ```

=== "Example"
    ```
    Raw: 100 CPU cores
    Utilization: 0.7 (30% overhead)
    Efficiency: 0.8 (25% coordination cost)
    Effective: 100 √ó 0.7 √ó 0.8 = 56 cores actual work
    ```

??? tip "üîß Try This: Find Your Breaking Point"
    ```bash
    # Local capacity test (DO NOT RUN IN PROD!)
    # Terminal 1: Start a simple server
    python -m http.server 8000
    
    # Terminal 2: Find the limit
    ab -n 10000 -c 100 http://localhost:8000/
    # Watch for the cliff where latency spikes
    
    # Terminal 3: Monitor resources
    htop  # Watch CPU, memory
    iftop # Watch network
    iotop # Watch disk
    ```

#### Real Capacity Limits (2024 numbers)

| Component | Practical Limit | Notes |
|-----------|----------------|--------|
| PostgreSQL | 5000 connections | With connection pooling |
| Redis | 10K ops/sec/core | Single-threaded |
| Kafka | 1M messages/sec/broker | With proper tuning |
| Load Balancer | 100K concurrent connections | Hardware dependent |
| Docker | ~10K containers/host | Resource dependent |
| Kubernetes | 5000 nodes/cluster | etcd limitation |
| Elasticsearch | 1000 shards/node | Recommended maximum |

<div class="truth-box">

**Counter-Intuitive Truth** üí°

Running at 100% capacity means you're already over capacity. Systems need breathing room for spikes, garbage collection, and maintenance. Target 60-70% steady-state.

</div>

---

### Page 4: Saturation Graph & Little's Law Primer

!!! target "Learning Objective"
    Understand why systems cliff-dive at high utilization.

<div class="axiom-box">

**Little's Law - The Universal Queue Equation:**

```
L = Œª √ó W

Where:
L = Average number of items in system
Œª = Average arrival rate
W = Average time in system

This law is ALWAYS true for stable systems, regardless of:
- Distribution of arrivals
- Service time variance  
- Number of servers
- Queue discipline
```

</div>

#### The Saturation Curve

<div class="latency-ladder" style="font-family: monospace; background: #f5f5f5; padding: 2rem; border-radius: 8px;">

```
Response Time
    ‚îÇ
400ms‚îÇ                                    ‚ï±
    ‚îÇ                                  ‚ï±‚îÇ 
300ms‚îÇ                               ‚ï±  ‚îÇ THE CLIFF
    ‚îÇ                            ‚ï±     ‚îÇ
200ms‚îÇ                        ‚ï±        ‚îÇ
    ‚îÇ                     ‚ï±           ‚îÇ
100ms‚îÇ              ‚ï± ‚îÄ ‚îÄ             ‚îÇ
    ‚îÇ      ‚îÄ ‚îÄ ‚îÄ                     ‚îÇ
  0ms‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    0%   20%   40%   60%   80%  90% 95% 100%
                    Utilization ‚Üí
```

</div>

#### Why The Cliff Exists (First Principles)

=== "At Different Utilizations"
    | Utilization | Queue Wait Time | Total Response Time |
    |-------------|-----------------|-------------------|
    | 0% | 0 | Service time only |
    | 50% | Service time √ó 0.5 | 1.5 √ó service time |
    | 80% | Service time √ó 4 | 5 √ó service time |
    | 90% | Service time √ó 9 | 10 √ó service time |
    | 95% | Service time √ó 19 | 20 √ó service time |
    | 99% | Service time √ó 99 | 100 √ó service time! |

=== "Mathematical Proof"
    ```
    For M/M/1 queue:
    W = 1/(Œº - Œª)
    
    Where Œº = service rate, Œª = arrival rate
    Utilization œÅ = Œª/Œº
    
    Therefore:
    W = 1/(Œº(1 - œÅ))
    
    As œÅ ‚Üí 1, W ‚Üí ‚àû
    ```

<div class="failure-vignette">

**Real-World Manifestation: Uber's Surge Pricing Algorithm (2018)**

```yaml
Normal: 
  - 70% driver utilization
  - 2 min wait time
  
Rush hour:
  - 85% utilization
  - 5 min wait time
  
Big event:
  - 95% utilization
  - 20 min wait time
  
System breaks:
  - 99% utilization
  - Infinite wait
  
Solution: Surge pricing reduces Œª (demand)
```

</div>

#### Practical Applications Table

| Component | Safe Utilization | Danger Zone | Action at Danger |
|-----------|-----------------|-------------|------------------|
| **CPU** | 70% | >85% | Add cores/nodes |
| **Memory** | 80% | >90% | Increase RAM/swap |
| **Network** | 60% | >75% | Upgrade bandwidth |
| **Disk I/O** | 50% | >70% | Add SSDs/RAID |
| **Thread Pool** | 60% | >80% | Increase pool size |
| **Database Conn** | 50% | >70% | Add read replicas |

??? example "üîß Try This: Visualize Your Queue"
    ```python
    import matplotlib.pyplot as plt
    import numpy as np
    
    def response_time(utilization, service_time=100):
        """Calculate response time using M/M/1 model"""
        if utilization >= 1:
            return float('inf')
        return service_time / (1 - utilization)
    
    # Plot the cliff
    utils = np.linspace(0, 0.99, 100)
    response_times = [response_time(u) for u in utils]
    
    plt.figure(figsize=(10, 6))
    plt.plot(utils * 100, response_times)
    plt.axvline(x=80, color='orange', linestyle='--', label='Warning')
    plt.axvline(x=90, color='red', linestyle='--', label='Danger')
    plt.xlabel('Utilization %')
    plt.ylabel('Response Time (ms)')
    plt.title('The Utilization Cliff')
    plt.ylim(0, 1000)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()
    ```

#### Queue Taxonomy

!!! info "Queue Disciplines Compared"
    | Type | Fairness | Use Case | Trade-off |
    |------|----------|----------|-----------|
    | **FIFO** | Fair | Default choice | Head-of-line blocking |
    | **LIFO** | Unfair | Timeout scenarios | Recent requests served first |
    | **Priority** | Unfair | Critical ops first | Can starve low-priority |
    | **WFQ** | Fair | Prevent starvation | More complex |
    | **RED** | Proactive | Prevent congestion | Drops packets early |

---

### Page 5: AXIOM 3 ‚Äì Partial Failure

!!! target "Learning Objective"
    In distributed systems, failure is partial, not binary.

<div class="axiom-box">

**The Fundamental Difference:**

```
Monolithic Failure:  Works OR Dead (binary)
Distributed Failure: Works AND Broken (superposition)

"A distributed system is one where a machine you've
never heard of can cause your app to fail."
```

</div>