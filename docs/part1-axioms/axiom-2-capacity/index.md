# Axiom 2: Finite Capacity

!!! info "Prerequisites"
    - [Axiom 1: Latency](../axiom-1-latency/index.md)
    - Basic understanding of system resources

!!! tip "Quick Navigation"
    [â† Axiom 1](../axiom-1-latency/index.md) | 
    [Examples â†’](examples.md) | 
    [Exercises â†’](exercises.md) |
    [â†’ Next: Partial Failure](../axiom-3-failure/index.md)

!!! target "Learning Objective"
    Every resource has a breaking point; find it before production does.

## Core Concept

<div class="axiom-box">

**Core Principle:**

```
Every system component has finite:
- CPU cycles per second
- Memory bytes
- Network packets/sec  
- Disk IOPS
- Connection pool slots
- Thread count
- Queue depth

Corollary: Infinite scaling is a lie sold by cloud vendors
```

</div>

## The Thermodynamics Angle

!!! quote "Physics Connection"
    Just as energy cannot be created or destroyed, computational capacity cannot be materialized from nothing. It can only be moved (migration), transformed (optimization), or purchased (scaling).

## Scale-Up vs Scale-Out

```mermaid
graph TD
    A[Single Server<br/>Vertical Scaling] 
    B[Multiple Servers<br/>Horizontal Scaling]
    C[Global Distribution<br/>Edge Computing]
    
    A -->|Scale Out| B
    B -->|Global Scale| C
    
    style A fill:#E8F5E9,stroke:#4CAF50
    style B fill:#FFF3E0,stroke:#FF9800
    style C fill:#FFEBEE,stroke:#F44336
```

<div class="decision-box">

**ğŸ¯ Decision Tree: Scale-Up vs Scale-Out**

```
START: Need more capacity
  â”‚
  â”œâ”€ Is workload parallelizable?
  â”‚   â”œâ”€ NO â†’ Scale UP (bigger box)
  â”‚   â””â”€ YES â†’ Continue
  â”‚
  â”œâ”€ Is data easily partitioned?
  â”‚   â”œâ”€ NO â†’ Scale UP + Read replicas
  â”‚   â””â”€ YES â†’ Continue  
  â”‚
  â”œâ”€ Can tolerate eventual consistency?
  â”‚   â”œâ”€ NO â†’ Scale UP to limits, then shard carefully
  â”‚   â””â”€ YES â†’ Scale OUT (add nodes)
  â”‚
  â””â”€ Result: Your scaling strategy
```

</div>

## Capacity Arithmetic

### Formula
```
Effective Capacity = Raw Capacity Ã— Utilization Factor Ã— Efficiency Factor

Where:
- Utilization Factor = 1 - (idle + overhead)
- Efficiency Factor = 1 / (1 + coordination_cost)
```

### Example
```
Raw: 100 CPU cores
Utilization: 0.7 (30% overhead)
Efficiency: 0.8 (25% coordination cost)
Effective: 100 Ã— 0.7 Ã— 0.8 = 56 cores actual work
```

## Real Capacity Limits (2024)

| Component | Practical Limit | Notes |
|-----------|----------------|--------|
| PostgreSQL | 5000 connections | With connection pooling |
| Redis | 10K ops/sec/core | Single-threaded |
| Kafka | 1M messages/sec/broker | With proper tuning |
| Load Balancer | 100K concurrent connections | Hardware dependent |
| Docker | ~10K containers/host | Resource dependent |
| Kubernetes | 5000 nodes/cluster | etcd limitation |
| Elasticsearch | 1000 shards/node | Recommended maximum |

## Little's Law - The Foundation

<div class="axiom-box">

**Little's Law - The Universal Queue Equation:**

```
L = Î» Ã— W

Where:
L = Average number of items in system
Î» = Average arrival rate
W = Average time in system

This law is ALWAYS true for stable systems
```

</div>

## The Saturation Curve

<div class="latency-ladder" style="font-family: monospace; background: #f5f5f5; padding: 2rem; border-radius: 8px;">

```
Response Time
    â”‚
400msâ”‚                                    â•±
    â”‚                                  â•±â”‚ 
300msâ”‚                               â•±  â”‚ THE CLIFF
    â”‚                            â•±     â”‚
200msâ”‚                        â•±        â”‚
    â”‚                     â•±           â”‚
100msâ”‚              â•± â”€ â”€             â”‚
    â”‚      â”€ â”€ â”€                     â”‚
  0msâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€
    0%   20%   40%   60%   80%  90% 95% 100%
                    Utilization â†’
```

</div>

## Why The Cliff Exists

| Utilization | Queue Wait Time | Total Response Time |
|-------------|-----------------|-------------------|
| 0% | 0 | Service time only |
| 50% | Service time Ã— 0.5 | 1.5 Ã— service time |
| 80% | Service time Ã— 4 | 5 Ã— service time |
| 90% | Service time Ã— 9 | 10 Ã— service time |
| 95% | Service time Ã— 19 | 20 Ã— service time |
| 99% | Service time Ã— 99 | 100 Ã— service time! |

### Mathematical Proof
```
For M/M/1 queue:
W = 1/(Î¼ - Î»)

Where Î¼ = service rate, Î» = arrival rate
Utilization Ï = Î»/Î¼

Therefore:
W = 1/(Î¼(1 - Ï))

As Ï â†’ 1, W â†’ âˆ
```

## Practical Application

| Component | Safe Utilization | Danger Zone | Action at Danger |
|-----------|-----------------|-------------|------------------|
| **CPU** | 70% | >85% | Add cores/nodes |
| **Memory** | 80% | >90% | Increase RAM/swap |
| **Network** | 60% | >75% | Upgrade bandwidth |
| **Disk I/O** | 50% | >70% | Add SSDs/RAID |
| **Thread Pool** | 60% | >80% | Increase pool size |
| **Database Conn** | 50% | >70% | Add read replicas |

<div class="truth-box">

**Counter-Intuitive Truth** ğŸ’¡

Running at 100% capacity means you're already over capacity. Systems need breathing room for spikes, garbage collection, and maintenance. Target 60-70% steady-state.

</div>

## Queue Disciplines

!!! info "Queue Disciplines Compared"
    | Type | Fairness | Use Case | Trade-off |
    |------|----------|----------|-----------|
    | **FIFO** | Fair | Default choice | Head-of-line blocking |
    | **LIFO** | Unfair | Timeout scenarios | Recent requests served first |
    | **Priority** | Unfair | Critical ops first | Can starve low-priority |
    | **WFQ** | Fair | Prevent starvation | More complex |
    | **RED** | Proactive | Prevent congestion | Drops packets early |

## Related Concepts

- **[Axiom 1: Latency](../axiom-1-latency/index.md)**: Latency increases with load
- **[Axiom 3: Partial Failure](../axiom-3-failure/index.md)**: Capacity exhaustion causes failures
- **[Work Distribution](../../part2-pillars/pillar-1-work/index.md)**: Load balancing strategies

## Key Takeaways

!!! success "Remember"
    
    1. **Every resource has limits** - Find them before production does
    2. **The cliff is real** - Systems break suddenly at high utilization  
    3. **70-80% is the knee** - Stay below for stable performance
    4. **Little's Law always applies** - L = Î»W is universal
    5. **Capacity planning is risk management** - Not optimization

## Navigation

!!! tip "Continue Learning"
    
    **Deep Dive**: [Capacity Examples & Failures](examples.md) â†’
    
    **Practice**: [Capacity Exercises](exercises.md) â†’
    
    **Next Axiom**: [Axiom 3: Partial Failure](../axiom-3-failure/index.md) â†’
    
    **Jump to**: [Capacity Calculator](../../tools/capacity-planner.md) | [Part II](../../part2-pillars/index.md)