name: Content Quality Assurance

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'docs/architects-handbook/**/*.md'
      - 'docs/javascripts/**/*.js'
      - 'mkdocs.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'docs/architects-handbook/**/*.md'
      - 'docs/javascripts/**/*.js'
      - 'mkdocs.yml'
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      validation_level:
        description: 'Validation Level'
        required: true
        default: 'standard'
        type: choice
        options:
          - quick
          - standard
          - comprehensive

permissions:
  contents: read
  pull-requests: write
  actions: read

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  content-validation:
    name: Content Validation
    runs-on: ubuntu-latest
    outputs:
      validation-passed: ${{ steps.content-check.outputs.passed }}
      quality-score: ${{ steps.content-check.outputs.score }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml requests beautifulsoup4 markdownify

      - name: Run Content Validation
        id: content-check
        run: |
          echo "Running content validation..."
          cd ${{ github.workspace }}
          
          if python scripts/validate_content.py > validation_output.txt 2>&1; then
            echo "passed=true" >> $GITHUB_OUTPUT
            validation_passed=true
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            validation_passed=false
          fi
          
          # Extract quality score
          score=$(grep "Average Quality Score:" validation_output.txt | grep -o '[0-9]\+\.[0-9]\+' || echo "0")
          echo "score=$score" >> $GITHUB_OUTPUT
          
          echo "Content validation completed with score: $score"
          cat validation_output.txt
          
          if [ "$validation_passed" = "false" ]; then
            echo "❌ Content validation failed"
            exit 1
          else
            echo "✅ Content validation passed"
          fi

      - name: Upload Content Validation Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: content-validation-report
          path: |
            validation_report.json
            validation_output.txt
          retention-days: 30

  link-validation:
    name: Link Validation
    runs-on: ubuntu-latest
    outputs:
      links-passed: ${{ steps.link-check.outputs.passed }}
      broken-count: ${{ steps.link-check.outputs.broken-count }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Run Link Validation
        id: link-check
        run: |
          echo "Running link validation..."
          cd ${{ github.workspace }}
          
          if bash scripts/check_links.sh > link_output.txt 2>&1; then
            echo "passed=true" >> $GITHUB_OUTPUT
            links_passed=true
          else
            echo "passed=false" >> $GITHUB_OUTPUT  
            links_passed=false
          fi
          
          # Extract broken link count
          broken_count=$(grep -E "Total Issues:" link_validation_report.txt | grep -o '[0-9]\+' || echo "0")
          echo "broken-count=$broken_count" >> $GITHUB_OUTPUT
          
          echo "Link validation completed with $broken_count issues"
          cat link_output.txt
          
          # Show summary from report
          if [ -f link_validation_report.txt ]; then
            echo "=== Link Validation Summary ==="
            head -20 link_validation_report.txt
          fi

      - name: Upload Link Validation Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: link-validation-report
          path: |
            link_validation_report.txt
            link_output.txt
          retention-days: 30

  javascript-validation:
    name: JavaScript Validation
    runs-on: ubuntu-latest
    outputs:
      js-passed: ${{ steps.js-check.outputs.passed }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'package*.json'

      - name: Install JavaScript Dependencies
        run: |
          npm init -y
          npm install --save-dev eslint jshint

      - name: Validate JavaScript Files
        id: js-check
        run: |
          echo "Running JavaScript validation..."
          
          js_files=$(find docs/javascripts -name "*.js" -type f)
          if [ -z "$js_files" ]; then
            echo "No JavaScript files found"
            echo "passed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          validation_passed=true
          
          echo "Found JavaScript files:"
          echo "$js_files"
          
          # Basic syntax checking with Node.js
          for file in $js_files; do
            echo "Checking: $file"
            if ! node -c "$file"; then
              echo "❌ Syntax error in $file"
              validation_passed=false
            else
              echo "✅ $file is valid"
            fi
          done
          
          if [ "$validation_passed" = "true" ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "✅ All JavaScript files validated successfully"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "❌ JavaScript validation failed"
            exit 1
          fi

  performance-testing:
    name: Performance Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.validation_level == 'comprehensive'
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'package*.json'

      - name: Install Performance Tools
        run: |
          # Install Lighthouse CI and Lighthouse
          npm install -g @lhci/cli@0.13.x
          npm install -g lighthouse
          
          # Verify installations
          lhci --version
          lighthouse --version

      - name: Install MkDocs Dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          
          # Verify MkDocs installation
          mkdocs --version
          
      - name: Build Documentation Site
        run: |
          # Temporarily disable strict mode for performance testing
          cp mkdocs.yml mkdocs.yml.backup
          sed -i 's/strict: true/strict: false/g' mkdocs.yml
          
          # Build the site
          mkdocs build --verbose
          
          # Restore original config
          mv mkdocs.yml.backup mkdocs.yml
          
          # Verify build succeeded
          if [ ! -d "site" ] || [ ! -f "site/index.html" ]; then
            echo "Build failed - site not created properly"
            exit 1
          fi
          
          echo "Site built successfully"

      - name: Start Local Server
        run: |
          # Start MkDocs server in background
          mkdocs serve --dev-addr=127.0.0.1:8000 --no-reload &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          
          # Wait for server to start and verify it's running
          for i in {1..30}; do
            if curl -s http://127.0.0.1:8000 > /dev/null; then
              echo "Server started successfully on port 8000"
              break
            fi
            echo "Waiting for server to start... ($i/30)"
            sleep 2
          done
          
          # Final check
          if ! curl -s http://127.0.0.1:8000 > /dev/null; then
            echo "Server failed to start properly"
            kill $SERVER_PID 2>/dev/null || true
            exit 1
          fi

      - name: Run Lighthouse CI
        run: |
          # Run Lighthouse with error handling
          if timeout 180 lhci collect --url=http://127.0.0.1:8000 --numberOfRuns=1 --timeout=60000; then
            echo "Lighthouse data collection completed"
            
            # Run assertions with relaxed criteria for CI environment
            lhci assert --preset=lighthouse:no-pwa || echo "Some Lighthouse assertions failed but continuing..."
          else
            echo "Lighthouse collection failed, creating minimal report"
            mkdir -p .lighthouseci
            echo '{"summary": "Lighthouse failed to run in CI environment"}' > .lighthouseci/summary.json
          fi
          
      - name: Stop Local Server
        if: always()
        run: |
          if [ ! -z "$SERVER_PID" ]; then
            kill $SERVER_PID 2>/dev/null || true
            echo "Server stopped"
          fi

      - name: Upload Performance Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-report
          path: .lighthouseci/
          retention-days: 30
          if-no-files-found: warn

  accessibility-testing:
    name: Accessibility Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.validation_level == 'comprehensive'

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'package*.json'

      - name: Install Accessibility Tools
        run: |
          npm install -g @axe-core/cli pa11y-ci
          
          # Verify installations
          axe --version || echo "Axe CLI installed"
          pa11y-ci --version

      - name: Install MkDocs Dependencies for Accessibility
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          
          # Verify MkDocs installation
          mkdocs --version

      - name: Build Documentation Site for Accessibility
        run: |
          # Temporarily disable strict mode for accessibility testing
          cp mkdocs.yml mkdocs.yml.backup
          sed -i 's/strict: true/strict: false/g' mkdocs.yml
          
          # Build the site
          mkdocs build --verbose
          
          # Restore original config
          mv mkdocs.yml.backup mkdocs.yml
          
          # Verify build succeeded
          if [ ! -d "site" ] || [ ! -f "site/index.html" ]; then
            echo "Build failed - site not created properly"
            exit 1
          fi
          
          echo "Site built successfully for accessibility testing"

      - name: Start Local Server
        run: |
          # Start server for accessibility testing
          mkdocs serve --dev-addr=127.0.0.1:8000 --no-reload &
          ACCESSIBILITY_SERVER_PID=$!
          echo "ACCESSIBILITY_SERVER_PID=$ACCESSIBILITY_SERVER_PID" >> $GITHUB_ENV
          
          # Wait for server to start
          for i in {1..20}; do
            if curl -s http://127.0.0.1:8000 > /dev/null; then
              echo "Accessibility server started successfully"
              break
            fi
            echo "Waiting for accessibility server... ($i/20)"
            sleep 3
          done

      - name: Run Accessibility Tests
        run: |
          # Test key pages with error handling
          if timeout 120 axe http://127.0.0.1:8000/ --save accessibility-report.json 2>/dev/null; then
            echo "Axe accessibility test completed"
          else
            echo "Axe test failed, creating basic report"
            echo '{"violations": [], "summary": "Axe failed to run"}' > accessibility-report.json
          fi
          
          # Run pa11y with timeout and error handling
          if timeout 120 pa11y-ci http://127.0.0.1:8000/ --threshold 10 2>/dev/null; then
            echo "pa11y accessibility test completed"
          else
            echo "pa11y test failed or timed out, but continuing..."
          fi
          
      - name: Stop Accessibility Server
        if: always()
        run: |
          if [ ! -z "$ACCESSIBILITY_SERVER_PID" ]; then
            kill $ACCESSIBILITY_SERVER_PID 2>/dev/null || true
            echo "Accessibility server stopped"
          fi

      - name: Upload Accessibility Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: accessibility-report
          path: accessibility-report.json
          retention-days: 30
          if-no-files-found: warn

  quality-summary:
    name: Quality Summary
    runs-on: ubuntu-latest
    needs: [content-validation, link-validation, javascript-validation]
    if: always()

    steps:
      - name: Generate Quality Summary
        run: |
          echo "# Quality Assurance Summary" > quality_summary.md
          echo "Generated: $(date -u)" >> quality_summary.md
          echo "" >> quality_summary.md
          
          # Content validation results
          echo "## Content Validation" >> quality_summary.md
          if [ "${{ needs.content-validation.outputs.validation-passed }}" = "true" ]; then
            echo "✅ **PASSED** - Quality Score: ${{ needs.content-validation.outputs.quality-score }}" >> quality_summary.md
          else
            echo "❌ **FAILED** - Quality Score: ${{ needs.content-validation.outputs.quality-score }}" >> quality_summary.md
          fi
          echo "" >> quality_summary.md
          
          # Link validation results
          echo "## Link Validation" >> quality_summary.md
          if [ "${{ needs.link-validation.outputs.links-passed }}" = "true" ]; then
            echo "✅ **PASSED** - No broken links found" >> quality_summary.md
          else
            echo "❌ **FAILED** - ${{ needs.link-validation.outputs.broken-count }} issues found" >> quality_summary.md
          fi
          echo "" >> quality_summary.md
          
          # JavaScript validation results
          echo "## JavaScript Validation" >> quality_summary.md
          if [ "${{ needs.javascript-validation.outputs.js-passed }}" = "true" ]; then
            echo "✅ **PASSED** - All JavaScript files valid" >> quality_summary.md
          else
            echo "❌ **FAILED** - JavaScript validation errors found" >> quality_summary.md
          fi
          echo "" >> quality_summary.md
          
          # Overall status
          echo "## Overall Status" >> quality_summary.md
          
          content_passed="${{ needs.content-validation.outputs.validation-passed }}"
          links_passed="${{ needs.link-validation.outputs.links-passed }}"
          js_passed="${{ needs.javascript-validation.outputs.js-passed }}"
          
          if [ "$content_passed" = "true" ] && [ "$links_passed" = "true" ] && [ "$js_passed" = "true" ]; then
            echo "🎉 **ALL CHECKS PASSED** - Documentation quality is excellent!" >> quality_summary.md
            echo "overall_status=success" >> $GITHUB_ENV
          else
            echo "⚠️ **QUALITY ISSUES DETECTED** - Please review the detailed reports" >> quality_summary.md
            echo "overall_status=failure" >> $GITHUB_ENV
          fi
          
          cat quality_summary.md

      - name: Comment PR (if PR)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('quality_summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

      - name: Upload Quality Summary
        uses: actions/upload-artifact@v4
        with:
          name: quality-summary
          path: quality_summary.md
          retention-days: 30
          if-no-files-found: warn

      - name: Set Final Status
        run: |
          if [ "${{ env.overall_status }}" = "failure" ]; then
            echo "❌ Quality assurance checks failed"
            exit 1
          else
            echo "✅ Quality assurance checks passed"
          fi

  notification:
    name: Quality Notification
    runs-on: ubuntu-latest
    needs: [quality-summary]
    if: always() && (github.event_name == 'schedule' || github.event_name == 'push')

    steps:
      - name: Send Success Notification
        if: needs.quality-summary.result == 'success'
        run: |
          echo "Quality checks passed successfully!"
          # Add webhook or notification integration here

      - name: Send Failure Notification  
        if: needs.quality-summary.result == 'failure'
        run: |
          echo "Quality checks failed - immediate attention needed!"
          # Add webhook or notification integration here
          exit 1