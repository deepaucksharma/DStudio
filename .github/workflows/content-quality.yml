name: Content Quality Assurance

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'docs/architects-handbook/**/*.md'
      - 'docs/javascripts/**/*.js'
      - 'mkdocs.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'docs/architects-handbook/**/*.md'
      - 'docs/javascripts/**/*.js'
      - 'mkdocs.yml'
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      validation_level:
        description: 'Validation Level'
        required: true
        default: 'standard'
        type: choice
        options:
          - quick
          - standard
          - comprehensive

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'

jobs:
  content-validation:
    name: Content Validation
    runs-on: ubuntu-latest
    outputs:
      validation-passed: ${{ steps.content-check.outputs.passed }}
      quality-score: ${{ steps.content-check.outputs.score }}
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml requests beautifulsoup4 markdownify

      - name: Run Content Validation
        id: content-check
        run: |
          echo "Running content validation..."
          cd ${{ github.workspace }}
          
          if python scripts/validate_content.py > validation_output.txt 2>&1; then
            echo "passed=true" >> $GITHUB_OUTPUT
            validation_passed=true
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            validation_passed=false
          fi
          
          # Extract quality score
          score=$(grep "Average Quality Score:" validation_output.txt | grep -o '[0-9]\+\.[0-9]\+' || echo "0")
          echo "score=$score" >> $GITHUB_OUTPUT
          
          echo "Content validation completed with score: $score"
          cat validation_output.txt
          
          if [ "$validation_passed" = "false" ]; then
            echo "‚ùå Content validation failed"
            exit 1
          else
            echo "‚úÖ Content validation passed"
          fi

      - name: Upload Content Validation Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: content-validation-report
          path: |
            validation_report.json
            validation_output.txt
          retention-days: 30

  link-validation:
    name: Link Validation
    runs-on: ubuntu-latest
    outputs:
      links-passed: ${{ steps.link-check.outputs.passed }}
      broken-count: ${{ steps.link-check.outputs.broken-count }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Run Link Validation
        id: link-check
        run: |
          echo "Running link validation..."
          cd ${{ github.workspace }}
          
          if bash scripts/check_links.sh > link_output.txt 2>&1; then
            echo "passed=true" >> $GITHUB_OUTPUT
            links_passed=true
          else
            echo "passed=false" >> $GITHUB_OUTPUT  
            links_passed=false
          fi
          
          # Extract broken link count
          broken_count=$(grep -E "Total Issues:" link_validation_report.txt | grep -o '[0-9]\+' || echo "0")
          echo "broken-count=$broken_count" >> $GITHUB_OUTPUT
          
          echo "Link validation completed with $broken_count issues"
          cat link_output.txt
          
          # Show summary from report
          if [ -f link_validation_report.txt ]; then
            echo "=== Link Validation Summary ==="
            head -20 link_validation_report.txt
          fi

      - name: Upload Link Validation Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: link-validation-report
          path: |
            link_validation_report.txt
            link_output.txt
          retention-days: 30

  javascript-validation:
    name: JavaScript Validation
    runs-on: ubuntu-latest
    outputs:
      js-passed: ${{ steps.js-check.outputs.passed }}

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install JavaScript Dependencies
        run: |
          npm init -y
          npm install --save-dev eslint jshint

      - name: Validate JavaScript Files
        id: js-check
        run: |
          echo "Running JavaScript validation..."
          
          js_files=$(find docs/javascripts -name "*.js" -type f)
          if [ -z "$js_files" ]; then
            echo "No JavaScript files found"
            echo "passed=true" >> $GITHUB_OUTPUT
            exit 0
          fi
          
          validation_passed=true
          
          echo "Found JavaScript files:"
          echo "$js_files"
          
          # Basic syntax checking with Node.js
          for file in $js_files; do
            echo "Checking: $file"
            if ! node -c "$file"; then
              echo "‚ùå Syntax error in $file"
              validation_passed=false
            else
              echo "‚úÖ $file is valid"
            fi
          done
          
          if [ "$validation_passed" = "true" ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "‚úÖ All JavaScript files validated successfully"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "‚ùå JavaScript validation failed"
            exit 1
          fi

  performance-testing:
    name: Performance Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.validation_level == 'comprehensive'
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Performance Tools
        run: |
          npm install -g @lhci/cli@0.12.x
          npm install -g lighthouse

      - name: Build Documentation Site
        run: |
          pip install mkdocs-material
          mkdocs build

      - name: Start Local Server
        run: |
          mkdocs serve --dev-addr=127.0.0.1:8000 &
          sleep 10  # Wait for server to start

      - name: Run Lighthouse CI
        run: |
          lhci collect --url=http://127.0.0.1:8000 --numberOfRuns=3
          lhci assert --preset=lighthouse:recommended

      - name: Upload Performance Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-report
          path: .lighthouseci/
          retention-days: 30

  accessibility-testing:
    name: Accessibility Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.validation_level == 'comprehensive'

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Accessibility Tools
        run: |
          npm install -g @axe-core/cli pa11y-ci

      - name: Build Documentation Site
        run: |
          pip install mkdocs-material
          mkdocs build

      - name: Start Local Server
        run: |
          mkdocs serve --dev-addr=127.0.0.1:8000 &
          sleep 10

      - name: Run Accessibility Tests
        run: |
          # Test key pages
          axe http://127.0.0.1:8000/architects-handbook/ --save accessibility-report.json
          pa11y-ci --sitemap http://127.0.0.1:8000/sitemap.xml --threshold 5

      - name: Upload Accessibility Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: accessibility-report
          path: accessibility-report.json
          retention-days: 30

  quality-summary:
    name: Quality Summary
    runs-on: ubuntu-latest
    needs: [content-validation, link-validation, javascript-validation]
    if: always()

    steps:
      - name: Generate Quality Summary
        run: |
          echo "# Quality Assurance Summary" > quality_summary.md
          echo "Generated: $(date -u)" >> quality_summary.md
          echo "" >> quality_summary.md
          
          # Content validation results
          echo "## Content Validation" >> quality_summary.md
          if [ "${{ needs.content-validation.outputs.validation-passed }}" = "true" ]; then
            echo "‚úÖ **PASSED** - Quality Score: ${{ needs.content-validation.outputs.quality-score }}" >> quality_summary.md
          else
            echo "‚ùå **FAILED** - Quality Score: ${{ needs.content-validation.outputs.quality-score }}" >> quality_summary.md
          fi
          echo "" >> quality_summary.md
          
          # Link validation results
          echo "## Link Validation" >> quality_summary.md
          if [ "${{ needs.link-validation.outputs.links-passed }}" = "true" ]; then
            echo "‚úÖ **PASSED** - No broken links found" >> quality_summary.md
          else
            echo "‚ùå **FAILED** - ${{ needs.link-validation.outputs.broken-count }} issues found" >> quality_summary.md
          fi
          echo "" >> quality_summary.md
          
          # JavaScript validation results
          echo "## JavaScript Validation" >> quality_summary.md
          if [ "${{ needs.javascript-validation.outputs.js-passed }}" = "true" ]; then
            echo "‚úÖ **PASSED** - All JavaScript files valid" >> quality_summary.md
          else
            echo "‚ùå **FAILED** - JavaScript validation errors found" >> quality_summary.md
          fi
          echo "" >> quality_summary.md
          
          # Overall status
          echo "## Overall Status" >> quality_summary.md
          
          content_passed="${{ needs.content-validation.outputs.validation-passed }}"
          links_passed="${{ needs.link-validation.outputs.links-passed }}"
          js_passed="${{ needs.javascript-validation.outputs.js-passed }}"
          
          if [ "$content_passed" = "true" ] && [ "$links_passed" = "true" ] && [ "$js_passed" = "true" ]; then
            echo "üéâ **ALL CHECKS PASSED** - Documentation quality is excellent!" >> quality_summary.md
            echo "overall_status=success" >> $GITHUB_ENV
          else
            echo "‚ö†Ô∏è **QUALITY ISSUES DETECTED** - Please review the detailed reports" >> quality_summary.md
            echo "overall_status=failure" >> $GITHUB_ENV
          fi
          
          cat quality_summary.md

      - name: Comment PR (if PR)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('quality_summary.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

      - name: Upload Quality Summary
        uses: actions/upload-artifact@v4
        with:
          name: quality-summary
          path: quality_summary.md
          retention-days: 30

      - name: Set Final Status
        run: |
          if [ "${{ env.overall_status }}" = "failure" ]; then
            echo "‚ùå Quality assurance checks failed"
            exit 1
          else
            echo "‚úÖ Quality assurance checks passed"
          fi

  notification:
    name: Quality Notification
    runs-on: ubuntu-latest
    needs: [quality-summary]
    if: always() && (github.event_name == 'schedule' || github.event_name == 'push')

    steps:
      - name: Send Success Notification
        if: needs.quality-summary.result == 'success'
        run: |
          echo "Quality checks passed successfully!"
          # Add webhook or notification integration here

      - name: Send Failure Notification  
        if: needs.quality-summary.result == 'failure'
        run: |
          echo "Quality checks failed - immediate attention needed!"
          # Add webhook or notification integration here
          exit 1