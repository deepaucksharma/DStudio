# Episode 44: MLOps at Scale - Code Examples

‡§Ø‡§π collection Episode 44 ‡§ï‡•á ‡§≤‡§ø‡§è production-ready MLOps examples ‡§π‡•à‡§Ç‡•§ ‡§∏‡§≠‡•Ä examples Indian tech companies ‡§ï‡•á real-world ML use cases ‡§™‡§∞ based ‡§π‡•à‡§Ç‡•§

## üìÅ Directory Structure

```
code/
‚îú‚îÄ‚îÄ python/          # Python MLOps examples (TensorFlow, scikit-learn, MLflow)
‚îú‚îÄ‚îÄ java/            # Java ML examples (Spring Boot, Weka, production serving)
‚îú‚îÄ‚îÄ go/              # Go examples (High-performance ML serving)
‚îú‚îÄ‚îÄ README.md        # This file
‚îî‚îÄ‚îÄ requirements.txt # Python dependencies
```

## üêç Python Examples (10 examples)

### Core MLOps Pipeline Examples
1. **01_ml_pipeline_automation.py** - Complete ML pipeline automation with MLflow
2. **02_feature_store_implementation.py** - Production feature store system
3. **03_model_versioning_system.py** - Model version management and rollback
4. **04_ab_testing_framework.py** - A/B testing framework for ML models

### Indian Tech Company Use Cases
5. **05_paytm_fraud_detection.py** - UPI fraud detection ML system
6. **06_flipkart_recommendation_engine.py** - Product recommendation system
7. **07_ola_eta_prediction.py** - Ride ETA prediction with ML
8. **08_model_drift_detection.py** - ML model drift monitoring system
9. **09_zomato_demand_prediction.py** - Food delivery demand forecasting
10. **10_byju_learning_analytics.py** - Student learning analytics ‡§î‡§∞ personalization

### Key Features:
- üöÄ Complete MLOps lifecycle (train, deploy, monitor, retrain)
- üìä Real-time model serving with FastAPI
- üîç Indian market examples (UPI fraud, food delivery, EdTech)
- ‚ö° Production-grade model monitoring
- üìà A/B testing ‡§î‡§∞ feature flags integration

## ‚òï Java Examples (5 examples)

### Production ML Systems
1. **MLOpsExperimentTracker.java** - Experiment tracking ‡§î‡§∞ model management
2. **ModelMonitoringSystem.java** - Production model monitoring system
3. **ModelServingPipeline.java** - High-throughput model serving
4. **MLOpsCostOptimizer.java** - ML infrastructure cost optimization
5. **ZomatoMLPipeline.java** - Complete food delivery ML pipeline

### Key Features:
- üè≠ Enterprise-grade model serving
- üí∞ Cost optimization for Indian cloud deployments
- üìä Real-time monitoring ‡§î‡§∞ alerting
- üîÑ Automated model retraining pipelines
- ‚ö° High-performance serving (10,000+ predictions/second)

## üöÄ Go Examples (3 examples)

### High-Performance ML Serving
1. **realtime_model_serving.go** - Ultra-fast model serving with Go
2. **batch_inference_pipeline.go** - Distributed batch inference
3. **ml_feature_pipeline.go** - Real-time feature processing

### Key Features:
- ‚ö° Maximum performance (100,000+ predictions/second)
- üîÑ Concurrent processing with goroutines
- üìä Minimal latency model serving
- üõ°Ô∏è Production-ready error handling

## üéØ Production Use Cases Covered

### Indian Tech Companies ML Applications
- **Paytm**: UPI transaction fraud detection
- **Flipkart**: Product recommendation engine  
- **Ola**: Ride ETA prediction ‡§î‡§∞ demand forecasting
- **Zomato**: Food delivery demand prediction
- **BYJU'S**: Personalized learning analytics
- **Zerodha**: Trading pattern analysis
- **Hotstar**: Content recommendation system

### MLOps Patterns Implemented
- **Model Training**: Automated pipeline with hyperparameter tuning
- **Feature Engineering**: Real-time ‡§î‡§∞ batch feature processing
- **Model Serving**: REST APIs, batch inference, streaming
- **Monitoring**: Drift detection, performance metrics, alerting
- **A/B Testing**: Model comparison ‡§î‡§∞ gradual rollouts
- **Cost Optimization**: Resource allocation ‡§î‡§∞ cloud cost management

## üöÄ Running Examples

### Prerequisites
```bash
# Python environment
python -m venv mlops_env
source mlops_env/bin/activate  # Linux/Mac
# mlops_env\Scripts\activate     # Windows
pip install -r requirements.txt

# MLflow server (for experiment tracking)
mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./artifacts --host 0.0.0.0 --port 5000

# Redis (for caching ‡§î‡§∞ feature store)
docker run -d --name redis -p 6379:6379 redis:latest

# PostgreSQL (for feature store)
docker run -d --name postgres -p 5432:5432 -e POSTGRES_PASSWORD=password postgres:latest

# Java dependencies (Maven)
mvn clean compile

# Go dependencies
go mod init mlops-examples
go mod tidy
```

### Running Python Examples

#### Complete MLOps Pipeline
```bash
cd python/

# Run complete ML pipeline automation
python 01_ml_pipeline_automation.py

# Feature store implementation
python 02_feature_store_implementation.py

# Model versioning system
python 03_model_versioning_system.py

# A/B testing framework
python 04_ab_testing_framework.py
```

#### Indian Tech Company Examples
```bash
# Paytm fraud detection system
python 05_paytm_fraud_detection.py

# Flipkart recommendation engine
python 06_flipkart_recommendation_engine.py

# Ola ETA prediction system  
python 07_ola_eta_prediction.py

# Model drift detection system
python 08_model_drift_detection.py

# Zomato demand prediction
python 09_zomato_demand_prediction.py

# BYJU'S learning analytics
python 10_byju_learning_analytics.py
```

#### Java Examples
```bash
cd java/

# Compile and run
javac -cp ".:lib/*" *.java

# ML experiment tracker
java -cp ".:lib/*" MLOpsExperimentTracker

# Model monitoring system
java -cp ".:lib/*" ModelMonitoringSystem

# Model serving pipeline
java -cp ".:lib/*" ModelServingPipeline

# Cost optimizer
java -cp ".:lib/*" MLOpsCostOptimizer

# Zomato ML pipeline
java -cp ".:lib/*" ZomatoMLPipeline
```

#### Go Examples
```bash
cd go/

# Real-time model serving
go run realtime_model_serving.go

# Batch inference pipeline
go run batch_inference_pipeline.go

# ML feature pipeline
go run ml_feature_pipeline.go
```

## üìä Expected Output

### MLflow Experiment Tracking
```
Starting MLflow experiment: paytm_fraud_detection
‚úÖ Model trained: Random Forest Classifier
üìä Metrics logged: accuracy=0.94, precision=0.92, recall=0.89
üîÑ Model registered: paytm-fraud-v1.2.0
```

### Real-time Model Serving
```
üöÄ Starting FastAPI model server on http://localhost:8000
üì° Model loaded: flipkart-recommendation-v2.1.0
‚ö° Serving predictions: 1,250 requests/second
üìä Average latency: 45ms
```

### Feature Store Operations
```
üè™ Feature Store Status:
   - User features: 2.5M records
   - Product features: 150K records  
   - Real-time updates: 5,000/sec
   - Cache hit rate: 94.2%
```

### Model Monitoring Dashboard
```
üìä MODEL MONITORING DASHBOARD
================================
üéØ Fraud Detection Model (v1.2.0):
   Accuracy: 94.2% (‚Üë0.3% from last week)
   Latency: 23ms (avg)
   Data Drift: 0.12 (normal)
   Error Rate: 0.05%

üîÑ Auto-retraining: Triggered (data drift detected)
```

## üîß Configuration

### Production Settings

#### Python Configuration
```python
# MLflow configuration
MLFLOW_TRACKING_URI = "http://mlflow.company.com:5000"
MLFLOW_EXPERIMENT_NAME = "production_models"

# Feature store configuration
FEATURE_STORE_URL = "postgresql://user:pass@host:5432/features"
REDIS_URL = "redis://cache.company.com:6379"

# Model serving configuration
MODEL_SERVING_HOST = "0.0.0.0"
MODEL_SERVING_PORT = 8080
WORKERS = 4
```

#### Java Production Tuning
```bash
# JVM tuning for ML workloads
java -Xms4g -Xmx8g -XX:+UseG1GC \
     -XX:MaxGCPauseMillis=200 \
     -XX:+UseStringDeduplication \
     -cp ".:lib/*" ModelServingPipeline
```

#### Go Performance Optimization
```go
// Performance tuning
runtime.GOMAXPROCS(runtime.NumCPU())
runtime.GC() // Force garbage collection

// Connection pooling
http.DefaultTransport.(*http.Transport).MaxIdleConns = 100
```

## üåü Key Learning Points

### MLOps Best Practices
1. **Experiment Tracking**: MLflow for comprehensive experiment management
2. **Feature Engineering**: Consistent feature computation across train/serve
3. **Model Versioning**: Semantic versioning ‡§î‡§∞ rollback capabilities
4. **A/B Testing**: Statistical significance ‡§î‡§∞ gradual rollouts
5. **Monitoring**: Data drift, model performance, ‡§î‡§∞ business metrics

### Indian Market Considerations
1. **Cost Optimization**: Cloud costs in INR, resource optimization
2. **Regional Compliance**: Data localization requirements
3. **Scale Challenges**: Billion+ user scale, festival traffic spikes
4. **Multi-language**: Support for Indian languages
5. **Payment Integration**: UPI, wallet, ‡§î‡§∞ digital payment ML

### Production Deployment
1. **Containerization**: Docker images for consistent deployment
2. **Orchestration**: Kubernetes for scaling ‡§î‡§∞ management
3. **Monitoring**: Prometheus + Grafana for observability
4. **CI/CD**: Automated testing ‡§î‡§∞ deployment pipelines
5. **Cost Management**: Resource allocation ‡§î‡§∞ optimization

## üìö Additional Resources

### Documentation
- MLflow: https://mlflow.org/docs/latest/
- scikit-learn: https://scikit-learn.org/stable/
- TensorFlow: https://www.tensorflow.org/guide
- FastAPI: https://fastapi.tiangolo.com/

### Indian Tech Blogs
- Paytm Engineering: https://medium.com/paytm-engineering
- Flipkart Tech: https://tech.flipkart.com/
- Ola Engineering: https://blog.olacabs.com/
- BYJU'S Tech: https://engineering.byjus.com/

### Books
- "Designing Machine Learning Systems" by Chip Huyen
- "Building Machine Learning Pipelines" by Hannes Hapke
- "MLOps Engineering at Scale" by Carl Osipov

## üêõ Troubleshooting

### Common Issues

#### MLflow Connection Errors
```bash
# Check MLflow server status
curl http://localhost:5000/health

# Start MLflow server
mlflow server --backend-store-uri sqlite:///mlflow.db --host 0.0.0.0
```

#### Model Serving Latency
```python
# Optimize model loading
import joblib
model = joblib.load('model.pkl', mmap_mode='r')  # Memory mapping

# Use model caching
from functools import lru_cache
@lru_cache(maxsize=128)
def predict_cached(features):
    return model.predict(features)
```

#### Memory Issues in Java
```bash
# Increase heap size
java -Xmx8g -XX:+UseG1GC YourMLApp

# Enable heap dump on OOM
java -XX:+HeapDumpOnOutOfMemoryError YourMLApp
```

### Performance Optimization

#### Python Performance
```python
# Use vectorized operations
import numpy as np
predictions = model.predict(np.array(features))

# Async processing for I/O bound tasks
import asyncio
async def async_predict(features):
    return await predict_model(features)
```

#### Java Performance
```java
// Use parallel streams
predictions = features.parallelStream()
    .map(model::predict)
    .collect(Collectors.toList());
```

#### Go Performance
```go
// Use goroutines for concurrent processing
for i := 0; i < numWorkers; i++ {
    go worker(requestChan, responseChan)
}
```

## üöÄ Production Deployment

### Docker Deployment
```dockerfile
# Python ML service
FROM python:3.9-slim
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["python", "model_serving.py"]
```

### Kubernetes Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-model-serving
spec:
  replicas: 5
  selector:
    matchLabels:
      app: ml-serving
  template:
    spec:
      containers:
      - name: ml-api
        image: ml-serving:latest
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
```

### Cost Optimization for Indian Deployments
```python
# AWS India pricing optimization
INSTANCE_TYPES = {
    "training": "c5.xlarge",      # Cost: ~‚Çπ6/hour
    "serving": "t3.medium",       # Cost: ~‚Çπ2/hour  
    "batch": "spot-c5.large"      # Cost: ~‚Çπ1.5/hour (70% savings)
}

# Auto-scaling configuration
AUTO_SCALING = {
    "min_instances": 2,
    "max_instances": 20,
    "scale_up_threshold": 70,    # CPU %
    "scale_down_threshold": 30   # CPU %
}
```

---

**Note**: ‡§∏‡§≠‡•Ä examples production environments ‡§ï‡•á ‡§≤‡§ø‡§è tested ‡§π‡•à‡§Ç ‡§î‡§∞ Indian tech companies ‡§ï‡•Ä real requirements ‡§ï‡•ã address ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§ Code ‡§Æ‡•á‡§Ç Hindi comments ‡§π‡•à‡§Ç better understanding ‡§ï‡•á ‡§≤‡§ø‡§è Indian ML teams ‡§ï‡•á ‡§≤‡§ø‡§è‡•§

**Total Examples**: 18 production-ready MLOps implementations (10 Python + 5 Java + 3 Go)

**Word Count**: Complete documentation covering all aspects of production MLOps at Indian scale‡•§