#!/usr/bin/env python3
"""
Episode 13: CDC & Real-Time Data Pipelines
Example 5: Real-Time UPI Transaction Streaming System

‡§Ø‡§π example UPI transactions ‡§ï‡•Ä real-time streaming implement ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§
PhonePe, Google Pay, Paytm ‡§ú‡•à‡§∏‡•á payment platforms ‡§ï‡•á scale ‡§™‡§∞‡•§

Author: Distributed Systems Podcast Team
Context: Indian digital payments - UPI, wallets, real-time fraud detection
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, AsyncGenerator, Tuple
import uuid
from dataclasses import dataclass, asdict
from decimal import Decimal, ROUND_HALF_UP
import redis.asyncio as redis
from kafka import KafkaProducer, KafkaConsumer
from kafka.errors import KafkaError
import threading
import queue
import time
import hashlib
import hmac
from enum import Enum
import random
import string

# Hindi logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s [%(thread)d]',
    handlers=[
        logging.FileHandler('upi_streaming.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class TransactionStatus(Enum):
    """UPI transaction status - NPCI standard"""
    INITIATED = "INITIATED"
    PENDING = "PENDING"
    SUCCESS = "SUCCESS"
    FAILED = "FAILED"
    TIMEOUT = "TIMEOUT"
    DISPUTED = "DISPUTED"

class FraudRiskLevel(Enum):
    """Fraud detection risk levels"""
    LOW = "LOW"
    MEDIUM = "MEDIUM"
    HIGH = "HIGH"
    CRITICAL = "CRITICAL"

@dataclass
class UPITransaction:
    """
    UPI Transaction structure - NPCI compliant
    Mumbai local train ticket ‡§∏‡•á ‡§≤‡•á‡§ï‡§∞ Ambani ‡§ï‡•á bungalow ‡§§‡§ï ‡§∏‡§¨ ‡§ï‡•Å‡§õ
    """
    transaction_id: str
    upi_ref_id: str  # NPCI reference ID
    payer_vpa: str  # Virtual Payment Address
    payee_vpa: str
    amount: Decimal
    currency: str = "INR"
    merchant_id: Optional[str] = None
    merchant_category: Optional[str] = None
    description: str = ""
    transaction_type: str = "P2P"  # P2P, P2M, P2B
    payment_app: str = "PhonePe"  # PhonePe, GPay, Paytm
    bank_ref_no: Optional[str] = None
    status: TransactionStatus = TransactionStatus.INITIATED
    created_at: datetime = None
    completed_at: Optional[datetime] = None
    
    # Fraud detection fields
    device_id: str = ""
    ip_address: str = ""
    location: Dict[str, float] = None  # lat, lng
    risk_score: float = 0.0
    risk_level: FraudRiskLevel = FraudRiskLevel.LOW
    
    # Compliance fields
    compliance_checked: bool = False
    aml_status: str = "PENDING"
    kyc_verified: bool = True

@dataclass
class FraudAlert:
    """Fraud detection alert"""
    alert_id: str
    transaction_id: str
    rule_triggered: str
    risk_score: float
    alert_type: str
    description: str
    created_at: datetime
    status: str = "ACTIVE"

class UPITransactionGenerator:
    """
    Realistic UPI transaction generator - Indian payment patterns
    Mumbai ‡§∏‡•á Mangalore ‡§§‡§ï ‡§ï‡§æ payment behavior simulate ‡§ï‡§∞‡§§‡§æ ‡§π‡•à
    """
    
    def __init__(self):
        # Popular Indian VPAs ‡§î‡§∞ payment patterns
        self.indian_vpas = [
            "ravi@paytm", "priya@phonepe", "amit@gpay", "sneha@ybl",
            "rajesh@axisbank", "kavita@hdfcbank", "suresh@sbi",
            "pooja@icicibank", "vikram@kotak", "anita@ybl"
        ]
        
        self.merchant_categories = [
            "GROCERY", "RESTAURANT", "PETROL_PUMP", "MEDICAL",
            "EDUCATION", "MOBILE_RECHARGE", "DTH", "ELECTRICITY",
            "GAS", "WATER", "INSURANCE", "MUTUAL_FUND"
        ]
        
        self.merchant_names = [
            "BigBasket", "Swiggy", "Zomato", "BookMyShow",
            "IRCTC", "OLA", "UBER", "Jio", "Airtel",
            "BPCL", "HPCL", "Apollo Pharmacy", "1mg"
        ]
        
        self.payment_apps = ["PhonePe", "GPay", "Paytm", "BHIM", "Amazon Pay"]
        
        # Indian cities with coordinates
        self.indian_cities = [
            {"name": "Mumbai", "lat": 19.0760, "lng": 72.8777},
            {"name": "Delhi", "lat": 28.6139, "lng": 77.2090},
            {"name": "Bangalore", "lat": 12.9716, "lng": 77.5946},
            {"name": "Hyderabad", "lat": 17.3850, "lng": 78.4867},
            {"name": "Chennai", "lat": 13.0827, "lng": 80.2707},
            {"name": "Kolkata", "lat": 22.5726, "lng": 88.3639},
            {"name": "Pune", "lat": 18.5204, "lng": 73.8567},
            {"name": "Ahmedabad", "lat": 23.0225, "lng": 72.5714}
        ]
    
    def generate_realistic_transaction(self) -> UPITransaction:
        """
        Realistic UPI transaction generate ‡§ï‡§∞‡•ã - Indian payment patterns ‡§ï‡•á ‡§∏‡§æ‡§•
        """
        # Random selection with weighted probabilities
        is_merchant_payment = random.random() < 0.7  # 70% merchant payments
        
        transaction_id = f"TXN{datetime.now().strftime('%Y%m%d')}{uuid.uuid4().hex[:8].upper()}"
        upi_ref_id = f"{random.randint(100000000000, 999999999999)}"
        
        payer_vpa = random.choice(self.indian_vpas)
        
        if is_merchant_payment:
            # Merchant payment
            merchant_name = random.choice(self.merchant_names)
            payee_vpa = f"{merchant_name.lower().replace(' ', '')}@merchant"
            merchant_id = f"MER{random.randint(10000, 99999)}"
            merchant_category = random.choice(self.merchant_categories)
            transaction_type = "P2M"
            
            # Merchant payment amounts - realistic distribution
            if merchant_category in ["GROCERY", "RESTAURANT"]:
                amount = Decimal(str(random.randint(100, 2000)))
            elif merchant_category in ["PETROL_PUMP"]:
                amount = Decimal(str(random.randint(500, 3000)))
            elif merchant_category in ["MOBILE_RECHARGE", "DTH"]:
                amount = Decimal(str(random.choice([149, 199, 299, 399, 599])))
            else:
                amount = Decimal(str(random.randint(50, 5000)))
                
        else:
            # P2P payment
            payee_vpa = random.choice([vpa for vpa in self.indian_vpas if vpa != payer_vpa])
            merchant_id = None
            merchant_category = None
            transaction_type = "P2P"
            
            # P2P amounts - typically smaller
            amount = Decimal(str(random.randint(10, 2000)))
        
        # Location and device info
        city = random.choice(self.indian_cities)
        location = {
            "lat": city["lat"] + random.uniform(-0.1, 0.1),
            "lng": city["lng"] + random.uniform(-0.1, 0.1)
        }
        
        device_id = f"DEV{hashlib.md5(payer_vpa.encode()).hexdigest()[:10]}"
        ip_address = f"49.{random.randint(1, 255)}.{random.randint(1, 255)}.{random.randint(1, 255)}"  # Indian IP range
        
        payment_app = random.choice(self.payment_apps)
        
        # Generate description
        if is_merchant_payment:
            description = f"Payment to {merchant_name}"
        else:
            descriptions = ["Transfer", "Payment", "Split bill", "Refund", "Gift"]
            description = random.choice(descriptions)
        
        transaction = UPITransaction(
            transaction_id=transaction_id,
            upi_ref_id=upi_ref_id,
            payer_vpa=payer_vpa,
            payee_vpa=payee_vpa,
            amount=amount,
            merchant_id=merchant_id,
            merchant_category=merchant_category,
            description=description,
            transaction_type=transaction_type,
            payment_app=payment_app,
            device_id=device_id,
            ip_address=ip_address,
            location=location,
            created_at=datetime.now()
        )
        
        # Calculate fraud risk score
        transaction.risk_score = self.calculate_fraud_risk(transaction)
        transaction.risk_level = self.determine_risk_level(transaction.risk_score)
        
        return transaction
    
    def calculate_fraud_risk(self, transaction: UPITransaction) -> float:
        """
        Fraud risk score calculate ‡§ï‡§∞‡•ã - Indian payment patterns ‡§ï‡•á based ‡§™‡§∞
        """
        risk_score = 0.0
        
        # Amount-based risk
        if transaction.amount > Decimal('10000'):
            risk_score += 20.0
        elif transaction.amount > Decimal('5000'):
            risk_score += 10.0
        
        # Time-based risk (late night transactions)
        hour = transaction.created_at.hour
        if hour < 6 or hour > 23:
            risk_score += 15.0
        
        # Frequency risk (simulated)
        # Production ‡§Æ‡•á‡§Ç ‡§Ø‡§π‡§æ‡§Å actual user transaction history check ‡§π‡•ã‡§ó‡•Ä
        if random.random() < 0.1:  # 10% chance of suspicious frequency
            risk_score += 25.0
        
        # Location risk (simulated unusual location)
        if random.random() < 0.05:  # 5% chance of unusual location
            risk_score += 30.0
        
        # Device risk (simulated new/suspicious device)
        if random.random() < 0.03:  # 3% chance of suspicious device
            risk_score += 20.0
        
        return min(risk_score, 100.0)  # Max risk score 100
    
    def determine_risk_level(self, risk_score: float) -> FraudRiskLevel:
        """Risk score ‡§ï‡•á based ‡§™‡§∞ risk level determine ‡§ï‡§∞‡•ã"""
        if risk_score >= 70:
            return FraudRiskLevel.CRITICAL
        elif risk_score >= 50:
            return FraudRiskLevel.HIGH
        elif risk_score >= 25:
            return FraudRiskLevel.MEDIUM
        else:
            return FraudRiskLevel.LOW

class UPITransactionStreamer:
    """
    UPI Transaction streaming system - PhonePe/GPay scale
    Mumbai local train ‡§ï‡•Ä frequency ‡§™‡§∞ transactions process ‡§ï‡§∞‡§§‡§æ ‡§π‡•à
    """
    
    def __init__(self, kafka_bootstrap_servers: List[str], redis_url: str):
        self.kafka_servers = kafka_bootstrap_servers
        self.redis_url = redis_url
        
        # Kafka components
        self.producer = None
        self.consumers = {}
        
        # Redis for caching and real-time data
        self.redis_client = None
        
        # Transaction generator
        self.transaction_generator = UPITransactionGenerator()
        
        # Processing components
        self.running = False
        self.processing_threads = []
        
        # Metrics
        self.metrics = {
            'transactions_generated': 0,
            'transactions_processed': 0,
            'fraud_alerts_generated': 0,
            'successful_transactions': 0,
            'failed_transactions': 0
        }
        
        # Kafka topics
        self.topics = {
            'transactions': 'upi.transactions',
            'fraud_alerts': 'upi.fraud.alerts',
            'status_updates': 'upi.status.updates',
            'compliance': 'upi.compliance.checks',
            'analytics': 'upi.analytics.events'
        }
    
    async def initialize(self):
        """
        Streaming system initialize ‡§ï‡§∞‡•ã
        """
        logger.info("üí∞ Initializing UPI Transaction Streaming System")
        
        try:
            # Initialize Kafka producer
            self.producer = KafkaProducer(
                bootstrap_servers=self.kafka_servers,
                value_serializer=lambda x: json.dumps(x, default=str).encode('utf-8'),
                key_serializer=lambda x: x.encode('utf-8'),
                compression_type='snappy',  # Better performance for high throughput
                batch_size=16384,
                linger_ms=10,
                acks='all',  # Ensure reliability for financial transactions
                retries=3
            )
            
            # Initialize Redis client
            self.redis_client = await redis.from_url(self.redis_url)
            
            # Create Kafka topics if needed
            await self.create_kafka_topics()
            
            logger.info("‚úÖ UPI Streaming System initialized successfully")
            
        except Exception as e:
            logger.error(f"üí• Initialization failed: {str(e)}")
            raise
    
    async def create_kafka_topics(self):
        """
        Kafka topics create ‡§ï‡§∞‡•ã - production ready configuration
        """
        # Production ‡§Æ‡•á‡§Ç ‡§Ü‡§™ Kafka Admin API use ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á
        logger.info("üì° Kafka topics ready for UPI streaming")
    
    def start_transaction_generator(self, transactions_per_second: int = 100):
        """
        Transaction generation start ‡§ï‡§∞‡•ã - Mumbai rush hour intensity
        """
        logger.info(f"üè≠ Starting transaction generator: {transactions_per_second} TPS")
        
        def transaction_generator_worker():
            """Transaction generation worker - continuous stream"""
            while self.running:
                try:
                    # Generate batch of transactions
                    batch_size = min(10, transactions_per_second)
                    
                    for _ in range(batch_size):
                        transaction = self.transaction_generator.generate_realistic_transaction()
                        
                        # Send to Kafka
                        self.send_transaction_to_kafka(transaction)
                        
                        # Update metrics
                        self.metrics['transactions_generated'] += 1
                        
                        # Fraud detection check
                        if transaction.risk_level in [FraudRiskLevel.HIGH, FraudRiskLevel.CRITICAL]:
                            self.generate_fraud_alert(transaction)
                    
                    # Control TPS
                    time.sleep(1.0 / (transactions_per_second / batch_size))
                    
                except Exception as e:
                    logger.error(f"üí• Transaction generation error: {str(e)}")
                    time.sleep(1)
        
        # Start generator thread
        generator_thread = threading.Thread(target=transaction_generator_worker, daemon=True)
        generator_thread.start()
        self.processing_threads.append(generator_thread)
        
        logger.info("‚úÖ Transaction generator started")
    
    def send_transaction_to_kafka(self, transaction: UPITransaction):
        """
        Transaction ‡§ï‡•ã Kafka ‡§Æ‡•á‡§Ç send ‡§ï‡§∞‡•ã - multiple topics ‡§™‡§∞
        """
        try:
            transaction_data = asdict(transaction)
            
            # Main transactions topic
            self.producer.send(
                topic=self.topics['transactions'],
                key=transaction.transaction_id,
                value=transaction_data
            )
            
            # Analytics topic for real-time metrics
            analytics_data = {
                'transaction_id': transaction.transaction_id,
                'amount': float(transaction.amount),
                'payment_app': transaction.payment_app,
                'transaction_type': transaction.transaction_type,
                'merchant_category': transaction.merchant_category,
                'risk_score': transaction.risk_score,
                'timestamp': transaction.created_at.isoformat()
            }
            
            self.producer.send(
                topic=self.topics['analytics'],
                key=transaction.transaction_id,
                value=analytics_data
            )
            
            # High-risk transactions to compliance topic
            if transaction.risk_level in [FraudRiskLevel.HIGH, FraudRiskLevel.CRITICAL]:
                compliance_data = {
                    'transaction_id': transaction.transaction_id,
                    'payer_vpa': transaction.payer_vpa,
                    'payee_vpa': transaction.payee_vpa,
                    'amount': float(transaction.amount),
                    'risk_score': transaction.risk_score,
                    'risk_level': transaction.risk_level.value,
                    'requires_review': True,
                    'timestamp': transaction.created_at.isoformat()
                }
                
                self.producer.send(
                    topic=self.topics['compliance'],
                    key=transaction.transaction_id,
                    value=compliance_data
                )
            
        except Exception as e:
            logger.error(f"üí• Kafka send error: {str(e)}")
    
    def generate_fraud_alert(self, transaction: UPITransaction):
        """
        Fraud alert generate ‡§ï‡§∞‡•ã - suspicious transactions ‡§ï‡•á ‡§≤‡§ø‡§è
        """
        try:
            alert = FraudAlert(
                alert_id=f"ALERT{uuid.uuid4().hex[:8].upper()}",
                transaction_id=transaction.transaction_id,
                rule_triggered=f"High risk score: {transaction.risk_score}",
                risk_score=transaction.risk_score,
                alert_type=transaction.risk_level.value,
                description=f"Suspicious {transaction.transaction_type} transaction: ‚Çπ{transaction.amount}",
                created_at=datetime.now()
            )
            
            # Send alert to Kafka
            alert_data = asdict(alert)
            self.producer.send(
                topic=self.topics['fraud_alerts'],
                key=alert.alert_id,
                value=alert_data
            )
            
            self.metrics['fraud_alerts_generated'] += 1
            
            logger.warning(f"üö® Fraud alert generated: {alert.alert_id} for transaction {transaction.transaction_id}")
            
        except Exception as e:
            logger.error(f"üí• Fraud alert generation error: {str(e)}")
    
    def start_transaction_processor(self):
        """
        Transaction processing start ‡§ï‡§∞‡•ã - status updates ‡§î‡§∞ completion
        """
        logger.info("‚öôÔ∏è Starting transaction processor")
        
        def transaction_processor_worker():
            """Transaction processing worker"""
            try:
                consumer = KafkaConsumer(
                    self.topics['transactions'],
                    bootstrap_servers=self.kafka_servers,
                    value_deserializer=lambda x: json.loads(x.decode('utf-8')),
                    group_id='upi-transaction-processor',
                    auto_offset_reset='latest'
                )
                
                for message in consumer:
                    if not self.running:
                        break
                    
                    try:
                        transaction_data = message.value
                        await self.process_transaction(transaction_data)
                        self.metrics['transactions_processed'] += 1
                        
                    except Exception as e:
                        logger.error(f"üí• Transaction processing error: {str(e)}")
                
                consumer.close()
                
            except Exception as e:
                logger.error(f"üí• Transaction processor error: {str(e)}")
        
        # Start processor thread
        processor_thread = threading.Thread(target=transaction_processor_worker, daemon=True)
        processor_thread.start()
        self.processing_threads.append(processor_thread)
        
        logger.info("‚úÖ Transaction processor started")
    
    async def process_transaction(self, transaction_data: Dict[str, Any]):
        """
        Individual transaction process ‡§ï‡§∞‡•ã - bank integration ‡§î‡§∞ status update
        """
        try:
            transaction_id = transaction_data['transaction_id']
            amount = Decimal(str(transaction_data['amount']))
            risk_score = transaction_data['risk_score']
            
            # Simulate processing delay based on amount and risk
            processing_delay = 0.1 + (float(amount) / 10000) + (risk_score / 1000)
            await asyncio.sleep(min(processing_delay, 2.0))  # Max 2 second delay
            
            # Simulate success/failure based on risk level
            success_probability = max(0.9 - (risk_score / 200), 0.5)  # Higher risk = lower success rate
            
            if random.random() < success_probability:
                new_status = TransactionStatus.SUCCESS
                self.metrics['successful_transactions'] += 1
            else:
                new_status = TransactionStatus.FAILED
                self.metrics['failed_transactions'] += 1
            
            # Send status update
            status_update = {
                'transaction_id': transaction_id,
                'status': new_status.value,
                'completed_at': datetime.now().isoformat(),
                'bank_ref_no': f"BNK{random.randint(100000000, 999999999)}",
                'processing_time_ms': processing_delay * 1000
            }
            
            self.producer.send(
                topic=self.topics['status_updates'],
                key=transaction_id,
                value=status_update
            )
            
            # Update Redis cache for real-time queries
            await self.redis_client.setex(
                f"transaction_status:{transaction_id}",
                300,  # 5 minutes TTL
                json.dumps(status_update, default=str)
            )
            
            logger.info(f"‚úÖ Transaction processed: {transaction_id} -> {new_status.value}")
            
        except Exception as e:
            logger.error(f"üí• Transaction processing error: {str(e)}")
    
    def start_fraud_alert_processor(self):
        """
        Fraud alert processing start ‡§ï‡§∞‡•ã
        """
        logger.info("üîç Starting fraud alert processor")
        
        def fraud_processor_worker():
            """Fraud alert processing worker"""
            try:
                consumer = KafkaConsumer(
                    self.topics['fraud_alerts'],
                    bootstrap_servers=self.kafka_servers,
                    value_deserializer=lambda x: json.loads(x.decode('utf-8')),
                    group_id='upi-fraud-processor',
                    auto_offset_reset='latest'
                )
                
                for message in consumer:
                    if not self.running:
                        break
                    
                    try:
                        alert_data = message.value
                        self.handle_fraud_alert(alert_data)
                        
                    except Exception as e:
                        logger.error(f"üí• Fraud alert processing error: {str(e)}")
                
                consumer.close()
                
            except Exception as e:
                logger.error(f"üí• Fraud processor error: {str(e)}")
        
        # Start fraud processor thread
        fraud_thread = threading.Thread(target=fraud_processor_worker, daemon=True)
        fraud_thread.start()
        self.processing_threads.append(fraud_thread)
        
        logger.info("‚úÖ Fraud alert processor started")
    
    def handle_fraud_alert(self, alert_data: Dict[str, Any]):
        """
        Fraud alert handle ‡§ï‡§∞‡•ã - immediate action ‡§≤‡•á‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è
        """
        try:
            alert_id = alert_data['alert_id']
            transaction_id = alert_data['transaction_id']
            risk_score = alert_data['risk_score']
            
            logger.warning(f"üö® Processing fraud alert: {alert_id} for transaction {transaction_id}")
            
            # Immediate actions based on risk level
            if risk_score >= 70:
                # Critical risk - block transaction
                logger.critical(f"üõë BLOCKING transaction {transaction_id} - Critical risk detected")
                
                # Send block command
                block_command = {
                    'transaction_id': transaction_id,
                    'action': 'BLOCK',
                    'reason': 'High fraud risk detected',
                    'alert_id': alert_id,
                    'timestamp': datetime.now().isoformat()
                }
                
                self.producer.send(
                    topic=self.topics['status_updates'],
                    key=transaction_id,
                    value=block_command
                )
                
            elif risk_score >= 50:
                # High risk - manual review
                logger.warning(f"‚ö†Ô∏è FLAGGING transaction {transaction_id} for manual review")
                
                # Send for manual review
                review_request = {
                    'transaction_id': transaction_id,
                    'alert_id': alert_id,
                    'risk_score': risk_score,
                    'requires_manual_review': True,
                    'priority': 'HIGH',
                    'timestamp': datetime.now().isoformat()
                }
                
                self.producer.send(
                    topic=self.topics['compliance'],
                    key=f"review_{transaction_id}",
                    value=review_request
                )
            
            # Log alert for audit
            logger.info(f"üìã Fraud alert logged: {alert_id}")
            
        except Exception as e:
            logger.error(f"üí• Fraud alert handling error: {str(e)}")
    
    async def get_real_time_metrics(self) -> Dict[str, Any]:
        """
        Real-time metrics return ‡§ï‡§∞‡•ã - dashboard ‡§ï‡•á ‡§≤‡§ø‡§è
        """
        try:
            # Calculate TPS
            current_time = datetime.now()
            one_minute_ago = current_time - timedelta(minutes=1)
            
            # Get transaction counts from Redis (if implemented)
            # For demo, using in-memory metrics
            
            metrics = {
                'timestamp': current_time.isoformat(),
                'transactions_per_second': round(self.metrics['transactions_generated'] / 60, 2),
                'total_transactions': self.metrics['transactions_generated'],
                'successful_transactions': self.metrics['successful_transactions'],
                'failed_transactions': self.metrics['failed_transactions'],
                'fraud_alerts': self.metrics['fraud_alerts_generated'],
                'success_rate': round((self.metrics['successful_transactions'] / max(self.metrics['transactions_processed'], 1)) * 100, 2),
                'processing_status': 'RUNNING' if self.running else 'STOPPED'
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"üí• Metrics calculation error: {str(e)}")
            return {'error': str(e)}
    
    async def start(self, transactions_per_second: int = 100):
        """
        Complete streaming system start ‡§ï‡§∞‡•ã
        """
        logger.info("üöÄ Starting UPI Transaction Streaming System")
        
        try:
            # Initialize system
            await self.initialize()
            
            # Mark as running
            self.running = True
            
            # Start all processors
            self.start_transaction_generator(transactions_per_second)
            self.start_transaction_processor()
            self.start_fraud_alert_processor()
            
            logger.info("‚úÖ UPI Streaming System started successfully")
            
            # Monitor and log metrics
            while self.running:
                await asyncio.sleep(30)
                metrics = await self.get_real_time_metrics()
                logger.info(f"üìä System Metrics: {json.dumps(metrics, indent=2)}")
            
        except Exception as e:
            logger.error(f"üí• System startup failed: {str(e)}")
            raise
    
    async def stop(self):
        """
        System ‡§ï‡•ã gracefully stop ‡§ï‡§∞‡•ã
        """
        logger.info("üõë Stopping UPI Streaming System")
        
        self.running = False
        
        # Wait for threads to complete
        for thread in self.processing_threads:
            thread.join(timeout=5)
        
        # Close connections
        if self.producer:
            self.producer.close()
        
        if self.redis_client:
            await self.redis_client.close()
        
        logger.info("‚úÖ UPI Streaming System stopped successfully")

async def main():
    """
    Main function - UPI streaming system demo
    """
    logger.info("üáÆüá≥ Starting Indian UPI Transaction Streaming Demo")
    
    # Configuration
    kafka_servers = ['localhost:9092']
    redis_url = 'redis://localhost:6379'
    transactions_per_second = 50  # Start with 50 TPS
    
    # Initialize streaming system
    upi_streamer = UPITransactionStreamer(kafka_servers, redis_url)
    
    try:
        # Start the streaming system
        await upi_streamer.start(transactions_per_second)
        
    except KeyboardInterrupt:
        logger.info("üõë Received interrupt signal")
        await upi_streamer.stop()
    except Exception as e:
        logger.error(f"üí• Unexpected error: {str(e)}")
        await upi_streamer.stop()

if __name__ == "__main__":
    asyncio.run(main())

"""
Production Deployment Guide:

1. Infrastructure Requirements:
   - Kafka cluster: Minimum 3 brokers with replication factor 3
   - Redis cluster for caching and session management
   - High-performance compute instances for processing
   - Load balancers for horizontal scaling

2. Security & Compliance:
   - End-to-end encryption for all transactions
   - PCI DSS compliance for payment data
   - PII masking and tokenization
   - Audit logging for regulatory compliance
   - RBAC for system access

3. Fraud Detection:
   - Machine learning models for real-time scoring
   - Rule-based fraud detection engines
   - Velocity checks and pattern analysis
   - Device fingerprinting
   - Geolocation validation

4. Performance Optimization:
   - Kafka partitioning by payment app or region
   - Connection pooling for database operations
   - Async processing for non-blocking operations
   - Batch processing for bulk operations

5. Monitoring & Alerting:
   - Transaction processing metrics
   - Fraud detection accuracy metrics
   - System health monitoring
   - Business KPIs (success rate, TPS)
   - Real-time dashboards

6. Indian Payment Ecosystem:
   - NPCI integration for UPI processing
   - Bank integration APIs
   - Regulatory compliance (RBI guidelines)
   - Multi-language support
   - Regional payment preferences

7. Disaster Recovery:
   - Multi-region deployment
   - Real-time data replication
   - Automated failover mechanisms
   - Data backup and recovery procedures
"""